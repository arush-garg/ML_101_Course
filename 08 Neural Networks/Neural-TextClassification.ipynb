{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on introduction to ML training\n",
    "So far, we have worked with simple, tabular data. In this notebook, we will learn how to deal with text in a sentiment analysis problem with a neural network architecture.\n",
    "\n",
    "### Step 1: Load and explore data\n",
    "The first step is figuring out the data source. In this case we will use a pre-existing dataset. We will:\n",
    "1. Create a folder 'data'\n",
    "2. Download the file from public github repo using python package \"requests\" and save the IMDB_Data.csv file in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: 'data'\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True #Helps with auto-complete\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir('data')\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "import requests, csv\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/techno-nerd/ML_101_Course/main/08%20Neural%20Networks/data/IMDB_Data.csv'\n",
    "r = requests.get(url)\n",
    "with open('data/IMDB_Data.csv', 'w') as f:\n",
    "  writer = csv.writer(f)\n",
    "  for line in r.iter_lines():\n",
    "    writer.writerow(line.decode('utf-8').split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/IMDB_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     1000 non-null   object\n",
      " 1   sentiment  1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Kaggle Dataset](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)\n",
    "\n",
    "This dataset is about movie reviews, and analysing their sentiment. Note that this dataset originally had 50,000 rows. Due to time constraints, the first 1000 rows have been saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"A wonderful little production. &lt;br /&gt;&lt;br /&gt;Th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"I thought this was a wonderful way to spend t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Petter Mattei's \"\"Love in the Time of Money\"\"...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  \"A wonderful little production. <br /><br />Th...  positive\n",
       "2  \"I thought this was a wonderful way to spend t...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  \"Petter Mattei's \"\"Love in the Time of Money\"\"...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    501\n",
       "negative    499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data preparation\n",
    "\n",
    "Normally, for Natural Language Processing (NLP), the following steps are usually taken:\n",
    "1. Removal of HTML content, like the \"\\<br\\>\" tags\n",
    "2. Removal of punctuations and special characters\n",
    "3. Removal of stopwords (\"is\", \"the\", \"a\", etc.), which are not significant\n",
    "4. Lemmatizing - Turning multiple words into a common root. For example, learnt, learning and learn to the root: Learn\n",
    "5. Vectorisation - Encoding the cleaning text into numerical values\n",
    "6. Replace \"positive\" and \"negative\" with 1 and 0 for the labels (sentiment)\n",
    "\n",
    "Then, we split the data into training (80%) and testing (20%)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 1:\n",
    "\n",
    "We will use the Beautiful Soup library to get rid of the HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "test_review = dataset['review'][1]\n",
    "soup = BeautifulSoup(test_review, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"\"has got all the polari\"\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done. A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"\"has got all the polari\"\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\"\n"
     ]
    }
   ],
   "source": [
    "print(test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"\"has got all the polari\"\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done. A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"\"has got all the polari\"\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\"\n"
     ]
    }
   ],
   "source": [
    "review = soup.get_text()\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_clean = pd.DataFrame()\n",
    "for i in dataset.index:\n",
    "    soup = BeautifulSoup(dataset['review'][i], \"html.parser\")\n",
    "    review = np.array(soup.get_text()).reshape((1, 1))\n",
    "    review = pd.DataFrame(review)\n",
    "    reviews_clean = pd.concat([reviews_clean, review], axis=0, ignore_index=True)\n",
    "\n",
    "reviews_clean.columns = ['review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  One of the other reviewers has mentioned that ...\n",
      "1  \"A wonderful little production. The filming te...\n",
      "2  \"I thought this was a wonderful way to spend t...\n",
      "3  Basically there's a family where a little boy ...\n",
      "4  \"Petter Mattei's \"\"Love in the Time of Money\"\"...\n"
     ]
    }
   ],
   "source": [
    "print(reviews_clean.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 2:\n",
    "\n",
    "We will use the re library to get rid of the punctuations and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for i in reviews_clean.index:\n",
    "    #Replace anything that is not alphabetical\n",
    "    review = re.sub('[^a-zA-Z]', ' ', reviews_clean['review'][i])\n",
    "    review = review.lower()\n",
    "\n",
    "    #Split the text into a list for iterating over words later\n",
    "    review = review.split()\n",
    "    reviews_clean.loc[i, 'review'] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  [one, of, the, other, reviewers, has, mentione...\n",
      "1  [a, wonderful, little, production, the, filmin...\n"
     ]
    }
   ],
   "source": [
    "print(reviews_clean.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 3:\n",
    "\n",
    "We will use the nltk library for removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "for i in reviews_clean.index:\n",
    "    review = [word for word in reviews_clean['review'][i] if not word in set(stopwords.words('english'))]\n",
    "    reviews_clean.loc[i, 'review'] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  [one, reviewers, mentioned, watching, oz, epis...\n",
      "1  [wonderful, little, production, filming, techn...\n"
     ]
    }
   ],
   "source": [
    "print(reviews_clean.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 4:\n",
    "\n",
    "Using the WordNetLemmatizer from nltk, we will turn the words into their original roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "for i in reviews_clean.index:\n",
    "    review = [lem.lemmatize(word) for word in reviews_clean['review'][i]]\n",
    "    review = ' '.join(review) #Turning the review back into a string\n",
    "    reviews_clean.loc[i, 'review'] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  one reviewer mentioned watching oz episode hoo...\n",
      "1  wonderful little production filming technique ...\n",
      "2  thought wonderful way spend time hot summer we...\n",
      "3  basically family little boy jake think zombie ...\n",
      "4  petter mattei love time money visually stunnin...\n"
     ]
    }
   ],
   "source": [
    "print(reviews_clean.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 5:\n",
    "\n",
    "We will use a CountVectorizer from sklearn to create an array of the number of times a word appears in the review. This will be used as the input for our model.\n",
    "\n",
    "This is one of many different vectorizers. Others include binary count vectorizer and TFIDF (Term Frequency Inverse Document Frequency) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "reviews_vec = count_vec.fit_transform(reviews_clean['review'])\n",
    "reviews_vec = reviews_vec.toarray()\n",
    "print(reviews_vec[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232927\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_vec[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 6:\n",
    "\n",
    "Using panda's in-built replace method, we will turn the label (sentiment) into a numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14016/3477691313.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  labels = dataset['sentiment'].replace({'positive':1, 'negative':0})\n"
     ]
    }
   ],
   "source": [
    "labels = dataset['sentiment'].replace({'positive':1, 'negative':0})\n",
    "labels = labels.to_numpy()\n",
    "print(labels[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, now that we have the data ready, we split it into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 232927)\n",
      "(200, 232927)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as ms\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = ms.train_test_split(reviews_vec, labels, test_size=0.2)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Selection and Training\n",
    "\n",
    "We will train a simple neural network to tackle this problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "Neural networks are made up of many interconnected nodes, as shown in the diagram below.\n",
    "\n",
    "![Simple NN](https://i0.wp.com/i.postimg.cc/pLgLsJDt/Architecture.jpg?w=1230&ssl=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Input Layer\n",
    "\n",
    "The input layer is as large as the feature space. In our scenario, it will be very big (almost 250k, the size of the dictionary)\n",
    "\n",
    "2. Hidden Layer\n",
    "\n",
    "The feature layer connects to the hidden layer in a Fully Connected Architecture. Here, every single input node connects to every single hidden layer node. Note that the size and number of hidden layers can be varied.\n",
    "\n",
    "3. Output layer\n",
    "\n",
    "All the hidden layer nodes connect to this node, which gives the final output. For a simple binary classification, we only need 1 output node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#This model has 1 hidden layer with 5 nodes.\n",
    "simple_nn = MLPClassifier(hidden_layer_sizes=(5,))\n",
    "simple_nn = simple_nn.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.00435038,  0.0031473 , -0.00372491, -0.00789322,  0.00729093],\n",
      "       [-0.00417278,  0.0066503 , -0.00725295, -0.00753269,  0.01225652],\n",
      "       [-0.00219081,  0.01111183, -0.00786482, -0.0026494 ,  0.01046321],\n",
      "       ...,\n",
      "       [-0.00740168,  0.00434013, -0.00715525, -0.00719045,  0.0097249 ],\n",
      "       [-0.00369909,  0.00369996, -0.00593024, -0.00700747,  0.01277009],\n",
      "       [-0.0038887 ,  0.00687893, -0.00931782, -0.00207341,  0.00459091]]), array([[ 0.65117036],\n",
      "       [-0.95226126],\n",
      "       [ 0.3269243 ],\n",
      "       [ 0.77982968],\n",
      "       [-1.00953001]])]\n"
     ]
    }
   ],
   "source": [
    "print(simple_nn.coefs_[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1164640\n"
     ]
    }
   ],
   "source": [
    "total_coefficients = sum(coef.size for coef in simple_nn.coefs_)\n",
    "print(total_coefficients)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the Model\n",
    "\n",
    "The evaluation metrics are the same for Neural Networks: Accuracy, Precision and Recall.\n",
    "\n",
    "We will compare these metrics to the performance of the other two models: SVM and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifierMetrics(labels, predictions):\n",
    "    total = labels.size\n",
    "    result = (labels == predictions)\n",
    "    correct = result.sum()\n",
    "    accuracy = (correct)/total\n",
    "\n",
    "    #Precision (correct '1' prediction / total '1' prediction)\n",
    "    precision = (result[predictions == 1.0].sum()) / (predictions == 1.0).sum()\n",
    "\n",
    "    #Recall = (correct '1' predictions / total number of '1's)\n",
    "\n",
    "    recall = (result[predictions == 1.0].sum()) / (labels == 1.0).sum()\n",
    "\n",
    "    return [accuracy, precision, recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Neural Network TEST Metrics:\n",
      "Accuracy: 0.81\n",
      "Precision: 0.7795275590551181\n",
      "Recall: 0.908256880733945\n"
     ]
    }
   ],
   "source": [
    "simple_nn_pred = simple_nn.predict(test_features)\n",
    "\n",
    "simple_nn_metrics = ClassifierMetrics(test_labels, simple_nn_pred)\n",
    "\n",
    "print(\"Simple Neural Network TEST Metrics:\")\n",
    "print(f\"Accuracy: {simple_nn_metrics[0]}\")\n",
    "print(f\"Precision: {simple_nn_metrics[1]}\")\n",
    "print(f\"Recall: {simple_nn_metrics[2]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For comparison\n",
    "\n",
    "|Model|Accuracy|Precision|Recall|\n",
    "|----|---------|---------|------|\n",
    "|SVM|0.825|0.804|0.830|\n",
    "|Random Forest|0.815|0.752|0.904|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it Yourself!\n",
    "\n",
    "Replace the \"text\" variable with your movie review and see if the models correctly identify your sentiment.\n",
    "\n",
    "In the preprocess function, each of the different steps have been performed to prepare the data for input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    #Regex\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "\n",
    "    #Stopwords\n",
    "    text = [word for word in text if not word in set(stopwords.words('english'))]\n",
    "\n",
    "    #Lemmatizing\n",
    "    text = [lem.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    #Vectorizing\n",
    "\n",
    "    text = count_vec.transform([text])\n",
    "    text = text.toarray()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your review is positive\n"
     ]
    }
   ],
   "source": [
    "text = \"Oppenheimer is an absolute masterpiece that brilliantly captures the complexity and intrigue of one of history's most enigmatic figures, J. Robert Oppenheimer. The film's storytelling is riveting, with outstanding performances that bring the characters to life. Director Christopher Nolan's meticulous attention to detail and cinematography are breathtaking, creating a visually stunning experience. The film's exploration of science, morality, and the human condition is thought-provoking and leaves a lasting impact. Oppenheimer is a must-see for anyone who appreciates powerful storytelling and outstanding filmmaking.\"\n",
    "text = preprocess(text)\n",
    "\n",
    "simple_nn_user_pred = simple_nn.predict(text)\n",
    "if simple_nn_user_pred == 0:\n",
    "    print(\"Your review is negative\")\n",
    "else:\n",
    "    print(\"Your review is positive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
