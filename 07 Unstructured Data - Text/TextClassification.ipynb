{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on introduction to ML training\n",
    "So far, we have worked with simple, tabular data. In this notebook, we will learn how to deal with text in a sentiment analysis problem.\n",
    "\n",
    "### Step 1: Load and explore data\n",
    "The first step is figuring out the data source. In this case we will use a pre-existing dataset. We will:\n",
    "1. Create a folder 'data'\n",
    "2. Download the file from public github repo using python package \"requests\" and save the IMDB_Data.csv file in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: 'data'\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True #Helps with auto-complete\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir('data')\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "\n",
    "import requests, csv\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/techno-nerd/ML_101_Course/main/07%20Unstructured%20Data%20-%20Text/data/IMDB_Data.csv'\n",
    "r = requests.get(url)\n",
    "with open('data/IMDB_Data.csv', 'w') as f:\n",
    "  writer = csv.writer(f)\n",
    "  for line in r.iter_lines():\n",
    "    writer.writerow(line.decode('utf-8').split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/IMDB_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     1000 non-null   object\n",
      " 1   sentiment  1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Kaggle Dataset](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)\n",
    "\n",
    "This dataset is about movie reviews, and analysing their sentiment. Note that this dataset originally had 50,000 rows. Due to time constraints, the first 1000 rows have been saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"A wonderful little production. &lt;br /&gt;&lt;br /&gt;Th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"I thought this was a wonderful way to spend t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Petter Mattei's \"\"Love in the Time of Money\"\"...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  \"A wonderful little production. <br /><br />Th...  positive\n",
       "2  \"I thought this was a wonderful way to spend t...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  \"Petter Mattei's \"\"Love in the Time of Money\"\"...  positive"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    501\n",
       "negative    499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data preparation\n",
    "\n",
    "Normally, for Natural Language Processing (NLP), the following steps are usually taken:\n",
    "1. Removal of HTML content, like the \"<br>\" tags\n",
    "2. Removal of punctuations and special characters\n",
    "3. Removal of stopwords (\"is\", \"the\", \"a\", etc.), which are not significant\n",
    "4. Lemmatizing - Turning multiple words into a common root. For example, learnt, learning and learn to the root: Learn\n",
    "5. Vectorisation - Encoding the cleaning text into numerical values\n",
    "6. Replace \"positive\" and \"negative\" with 1 and 0 for the labels (sentiment)\n",
    "\n",
    "Then, we split the data into training (80%) and testing (20%)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 1:\n",
    "\n",
    "We will use the Beautiful Soup library to get rid of the HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "test_review = dataset['review'][1]\n",
    "soup = BeautifulSoup(test_review, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"\"has got all the polari\"\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done. A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"\"has got all the polari\"\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\"\n"
     ]
    }
   ],
   "source": [
    "print(test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"\"has got all the polari\"\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done. A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"\"has got all the polari\"\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\"\n"
     ]
    }
   ],
   "source": [
    "review = soup.get_text()\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_clean = pd.DataFrame()\n",
    "for i in dataset.index:\n",
    "    soup = BeautifulSoup(dataset['review'][i], \"html.parser\")\n",
    "    review = np.array(soup.get_text()).reshape((1, 1))\n",
    "    review = pd.DataFrame(review)\n",
    "    reviews_clean = pd.concat([reviews_clean, review], axis=0, ignore_index=True)\n",
    "\n",
    "reviews_clean.columns = ['review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  One of the other reviewers has mentioned that ...\n",
      "1  \"A wonderful little production. The filming te...\n",
      "2  \"I thought this was a wonderful way to spend t...\n",
      "3  Basically there's a family where a little boy ...\n",
      "4  \"Petter Mattei's \"\"Love in the Time of Money\"\"...\n"
     ]
    }
   ],
   "source": [
    "print(reviews_clean.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 2:\n",
    "\n",
    "We will use the re library to get rid of the punctuations and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for i in reviews_clean.index:\n",
    "    #Replace anything that is not alphabetical\n",
    "    review = re.sub('[^a-zA-Z]', ' ', reviews_clean['review'][i])\n",
    "    review = review.lower()\n",
    "\n",
    "    #Split the text into a list for iterating over words later\n",
    "    review = review.split()\n",
    "    reviews_clean['review'][i] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  [one, of, the, other, reviewers, has, mentione...\n",
      "1  [a, wonderful, little, production, the, filmin...\n"
     ]
    }
   ],
   "source": [
    "print(reviews_clean.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 3:\n",
    "\n",
    "We will use the nltk library for removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/arushgarg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "for i in reviews_clean.index:\n",
    "    review = [word for word in reviews_clean['review'][i] if not word in set(stopwords.words('english'))]\n",
    "    reviews_clean['review'][i] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  [one, reviewers, mentioned, watching, oz, epis...\n",
      "1  [wonderful, little, production, filming, techn...\n"
     ]
    }
   ],
   "source": [
    "print(reviews_clean.head(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 4:\n",
    "\n",
    "Using the WordNetLemmatizer from nltk, we will turn the words into their original roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/arushgarg/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "for i in reviews_clean.index:\n",
    "    review = [lem.lemmatize(word) for word in reviews_clean['review'][i]]\n",
    "    review = ' '.join(review) #Turning the review back into a string\n",
    "    reviews_clean['review'][i] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  one reviewer mentioned watching oz episode hoo...\n",
      "1  wonderful little production filming technique ...\n",
      "2  thought wonderful way spend time hot summer we...\n",
      "3  basically family little boy jake think zombie ...\n",
      "4  petter mattei love time money visually stunnin...\n"
     ]
    }
   ],
   "source": [
    "print(reviews_clean.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 5:\n",
    "\n",
    "We will use a CountVectorizer from sklearn to create an array of the number of times a word appears in the review. This will be used as the input for our model.\n",
    "\n",
    "This is one of many different vectorizers. Others include binary count vectorizer and TFIDF (Term Frequency Inverse Document Frequency) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "reviews_vec = count_vec.fit_transform(reviews_clean['review'])\n",
    "reviews_vec = reviews_vec.toarray()\n",
    "print(reviews_vec[:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Step 6:\n",
    "\n",
    "Using panda's in-built replace method, we will turn the label (sentiment) into a numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "labels = dataset['sentiment'].replace({'positive':1, 'negative':0})\n",
    "labels = labels.to_numpy()\n",
    "print(labels[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, now that we have the data ready, we split it into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 232922)\n",
      "(200, 232922)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as ms\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = ms.train_test_split(reviews_vec, labels, test_size=0.2)\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Selection and Training\n",
    "\n",
    "Since the feature space is very large, we cannot use most stand-alone models, like Decision Trees or Logistic Regression. Hence, we will use a a Support Vector Machine (SVM) and a Random Forest (ensemble of decision trees)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM)\n",
    "\n",
    "SVMs are very powerful for this kind of problems, because they can handle the large feature space. They try to find an equation that separates the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(C=0.5) #The 'C' value tells the model to maximise accuracy, not margins\n",
    "svm = svm.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifierMetrics(labels, predictions):\n",
    "    total = labels.size\n",
    "    result = (labels == predictions)\n",
    "    correct = result.sum()\n",
    "    accuracy = (correct)/total\n",
    "\n",
    "    #Precision (correct '1' prediction / total '1' prediction)\n",
    "    precision = (result[predictions == 1.0].sum()) / (predictions == 1.0).sum()\n",
    "\n",
    "    #Recall = (correct '1' predictions / total number of '1's)\n",
    "\n",
    "    recall = (result[predictions == 1.0].sum()) / (labels == 1.0).sum()\n",
    "\n",
    "    return [accuracy, precision, recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM TEST Metrics:\n",
      "Accuracy: 0.825\n",
      "Precision: 0.8041237113402062\n",
      "Recall: 0.8297872340425532\n"
     ]
    }
   ],
   "source": [
    "svm_pred = svm.predict(test_features)\n",
    "svm_metrics = ClassifierMetrics(test_labels, svm_pred)\n",
    "\n",
    "print(\"SVM TEST Metrics:\")\n",
    "print(f\"Accuracy: {svm_metrics[0]}\")\n",
    "print(f\"Precision: {svm_metrics[1]}\")\n",
    "print(f\"Recall: {svm_metrics[2]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifiers\n",
    "\n",
    "Random Forests can also perform well on these kind of problems because of the way they divide features amongst the different trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "r_forest = RandomForestClassifier(n_estimators=500, min_samples_leaf=3)\n",
    "r_forest = r_forest.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM TEST Metrics:\n",
      "Accuracy: 0.815\n",
      "Precision: 0.7522123893805309\n",
      "Recall: 0.9042553191489362\n"
     ]
    }
   ],
   "source": [
    "r_forest_pred = r_forest.predict(test_features)\n",
    "r_forest_metrics = ClassifierMetrics(test_labels, r_forest_pred)\n",
    "\n",
    "print(\"SVM TEST Metrics:\")\n",
    "print(f\"Accuracy: {r_forest_metrics[0]}\")\n",
    "print(f\"Precision: {r_forest_metrics[1]}\")\n",
    "print(f\"Recall: {r_forest_metrics[2]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these models performed pretty well. In the next lesson, we will see how well neural networks, a completely different architecture, will perform."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it Yourself!\n",
    "\n",
    "Replace the \"text\" variable with your movie review and see if the models correctly identify your sentiment.\n",
    "\n",
    "In the preprocess function, each of the different steps have been performed to prepare the data for input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    #Regex\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "\n",
    "    #Stopwords\n",
    "    text = [word for word in text if not word in set(stopwords.words('english'))]\n",
    "\n",
    "    #Lemmatizing\n",
    "    text = [lem.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    #Vectorizing\n",
    "\n",
    "    text = count_vec.transform([text])\n",
    "    text = text.toarray()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your review is positive\n"
     ]
    }
   ],
   "source": [
    "text = \"Oppenheimer is an absolute masterpiece that brilliantly captures the complexity and intrigue of one of history's most enigmatic figures, J. Robert Oppenheimer. The film's storytelling is riveting, with outstanding performances that bring the characters to life. Director Christopher Nolan's meticulous attention to detail and cinematography are breathtaking, creating a visually stunning experience. The film's exploration of science, morality, and the human condition is thought-provoking and leaves a lasting impact. Oppenheimer is a must-see for anyone who appreciates powerful storytelling and outstanding filmmaking.\"\n",
    "text = preprocess(text)\n",
    "\n",
    "svm_user_pred = svm.predict(text)\n",
    "if svm_user_pred == 0:\n",
    "    print(\"Your review is negative\")\n",
    "else:\n",
    "    print(\"Your review is positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your review is positive\n"
     ]
    }
   ],
   "source": [
    "forest_user_pred = r_forest.predict(text)\n",
    "if forest_user_pred == 0:\n",
    "    print(\"Your review is negative\")\n",
    "else:\n",
    "    print(\"Your review is positive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
